% Тут используется класс, установленный на сервере Papeeria. На случай, если
% текст понадобится редактировать где-то в другом месте, рядом лежит файл matmex-diploma-custom.cls
% который в момент своего создания был идентичен классу, установленному на сервере.
% Для того, чтобы им воспользоваться, замените matmex-diploma на matmex-diploma-custom
% Если вы работаете исключительно в Papeeria то мы настоятельно рекомендуем пользоваться
% классом matmex-diploma, поскольку он будет автоматически обновляться по мере внесения корректив
%
\documentclass{matmex-diploma}

\usepackage{amsmath}

\begin{document}
% Год, город, название университета и факультета предопределены,
% но можно и поменять.
% Если англоязычная титульная страница не нужна, то ее можно просто удалить.
\filltitle{ru}{
    chair              = {Кафедра информационных систем и технологий},
    title              = {Разработка программного компонента для проведения сравнительного анализа биологических данный FAIRE-seq},
    % Здесь указывается тип работы. Возможные значения:
    %   coursework - Курсовая работа
    %   diploma - Диплом специалиста
    %   master - Диплом магистра
    %   bachelor - Диплом бакалавра
    type               = {bachelor},
    position           = {студента},
    group              = 4511,
    author             = {Бутомов Артем Сергеевич},
    supervisorPosition = {},
    supervisor         = {Лебедев Сергей Андреевич},
    reviewerPosition   = {аспирант},
    reviewer           = {Сергушичев Алексей Александрович},
    chairHeadPosition  = {},
    chairHead          = {},
    university         = {Санкт-Петербургский национальный исследовательский университет информационных технологий, механики и оптики},
    faculty            = {Факультет информационных технологий и программирования},
%   city               = {Санкт-Петербург},
%   year               = {2013}
}
\filltitle{en}{
    chair              = {Chair of Information Systems and Technologies},
    title              = {Development of a software component for a comparative analysis of the biological FAIRE-seq data},
    author             = {Artiom Butomov},
    supervisorPosition = {},
    supervisor         = {Sergei Lebedev},
    reviewerPosition   = {postgraduate},
    reviewer           = {Alexey Sergushichev},
    chairHeadPosition  = {},
    chairHead          = {},
    university         = {Saint Petersburg National Research University of Information Technologies, Mechanics and Optics},
    faculty            = {Faculty of Information Technology and Software Engineering},
}
\maketitle
\tableofcontents
% У введения нет номера главы
\section*{Введение}
ДНК (дезоксирибонуклеиновая кислота) --- длинная двухцепочечная молекула, являющаяся носителем генетической информации в биологических организмах.

Изучать пространственную структуру ДНК организма важно для понимания механизмов регуляции жизнидеятельности клетки.

Формальдегидная изоляция регуляторных элементов с последующим секвенированием (Formaldehyde-Assisted Isolation of Regulatory Elements sequencing, FAIRE-Seq) --- Это биологический протокол, позволяющий находить участки, в которых ДНК доступна для связывания белками. Суть работы метода заключается в том, что на ДНК, выделенную из клетки, "прикрепляют" нуклеосомы с помощью формальдегида. Затем ДНК фрагментируют с помощью ультразвука. После этого происходит "разделение" полученных фрагментов ДНК на две группы: участки связанные с белками и "свободные" участки. Далее "свободные" фрагменты "читают" с помощью секвенатора. И наконец, для каждого прочтения секвенатора определяют место в геноме исследуемого организма, откуда он был прочитан.

В контексте данной работы, геном "разбивается" на неперескающиеся отрезки фиксированной длины, называемые бинами. Подсчитывается количество прочтений, начинающихся внутри каждого отрезка. Таким образом, получатся вектор из неотрицательных целых чисел, именуемый вектором покрытия.

Из вектора покрытия можно сделать предположение о вероятности расплетения региона, чем больше значение элемента вектора, тем с большей вероятностью, что регион, соответствующий элементу, был расплетен.

Однако, рассматриваемый протокол не исключает возможности наличия ошибок в результатах биологического эксперемнта. Неточности метода FAIRE-seq обусловлены следующими моментами:
\begin{enumerate}
\item
Протокол работает с колонией клеток. Таким образом в результатах эксперимента мы видим некоторое среднее состояние по всем клеткам
\item
Этап фиксации не обладает 100\% КПД, то есть некоторые белки могут “отвалиться” 
\item
Этап разделения “свободных” и “связанных” фаз также неточен. Вместе со “свободными" вполне могут попасться и связанные фрагменты
\end{enumerate}

Так как в результате эксперемента появляется шум, данные FAIRE-seq удобно анализировать с помощью вероятностых моделей.

Цель данной работы - разработать математическую модель для проведения сравнительного анализа нескольких эксперементов биологический данных FAIRE-seq, научиться оценивать и контролировать число неверных предсказаний модели. 
\\\\
Для достижения цели были поставлены следующие задачи:
\begin{enumerate}
\item
Изучить предметную область
\item
Предложить несколько вероятностных моделей для сравнения экспериментов FAIRE-seq
\item
Реализовать модели в виде программы на языке Python
\item
Оценить эффективность полученной программы
\end{enumerate}

\section{Предлагаемые модели}
\subsection{Описание задачи}
\subsection{Смесь многомерных распределений Пуассона}

Таким образом с помощью наибольшего правдоподобия можно найти оценку последовательности скрытых состояний.
\\
\newcommand{\argmax}{\mathop{\rm arg~max}\limits}
$\hat{\theta}_{ML} = \argmax_{s \in {1,..,S}^N} \mathcal{P}(x,s|\theta)$

Моделировать количество прочтений вдоль генома с помощью смеси многомерных распределений Пуасона

Методом максимума правдоподобия найти решение довольно сложно, поскольку для этого требуется решить систему, где оцениваемые параметры зависят от наблюдаемой выборки $x$ и неизвестных значений скрытых состояний $s$. Асимптотическая сложность решения возрастет в $S^N$ раз.

Поэтому, будем искать приближенное решение с помощью EM-алгоритма, в котором правдоподобие оптимизируется до сходимости. Последовательность действий формируется следующим образом\cite{book:Bishop}:
\begin{enumerate}
\item
Инициализировать начальные значения параметров
\item
Вычислить нижнюю оценку на правдоподобие
\item
Найти новое значение параметров модели
\item
Вычислить логарифм правдоподобия и проверить на сходимость
\end{enumerate}

Выведем EM-алгоритм для смеси многомерных Пуасоновских испусканий.

\begin{equation}
\ln p(X;\pi,\lambda) = \sum_{n=1}^N \ln{\sum_{k=1}^K} \pi_k \mathcal{P}(x_n;\lambda_k)
\end{equation}

\begin{equation}
\gamma(z_{nk}) = \frac{\pi_k\mathcal{P}(x_n;\lambda_k)}{\sum_{j=1}^K\pi_j\mathcal{P}(x_n;\lambda_j)}
\end{equation}

\begin{equation}
\pi_{k}^* = \frac{N_k}{N}
\end{equation}

\subsection*{Шаг М}
% вместо |  - иполльзовать ;
$$\frac{\partial}{\partial \lambda_k}E[\log p(x|z;\theta)]$$
$$=\frac{\partial}{\partial \lambda_k}\sum_{n=1}^N \sum_{k=1}^K
E[z_{nk}]\{\log \pi_k + \log \mathcal{P}(x_n|\theta)\}$$
$$= \sum_{n=1}^N E[z_{nk}] \frac{\partial}{\partial \lambda_k} \log \mathcal{P}(x_n|\theta)$$
$$= \sum_{n=1}^N \gamma(z_{nk}) \frac{\partial}{\partial \lambda_k} \log {\frac{\lambda^{x_n} e^{-\lambda}}{x_n!}}$$
$$= \sum_{n=1}^N \gamma(z_{nk}) \frac{\partial}{\partial \lambda_k} (\log {\lambda_k}^{x_n} + \log e^{-\lambda_k} - \log x_n! )$$
$$= \sum_{n=1}^N \gamma(z_{nk}) \frac{\partial}{\partial \lambda_k} (x_n \log \lambda_k - \lambda_k - \log x_n! )$$
$$= \sum_{n=1}^N \gamma(z_{nk}) (\frac{x_n}{\lambda_k} - 1)= 0$$
\\\\
получаем
\begin{equation}
\lambda_k^* = \frac{1}{N_k}\sum_{n=1}^N\gamma(z_{nk})x_n
\end{equation}
\\\\
где
\begin{equation}
N_k = \sum_{n=1}^N\gamma(z_nk)
\end{equation}
Найдем новые значения априорных вероятностей.
Воспользуемся методом множителей Лагранжа для учета ограничений на вектор априорных вероятностей. 
$$\frac{\partial}{\partial \pi_k}( E[\log p(x|z;\theta)] + \lambda(\sum_{j=1}^K \pi_j - 1))$$
$$= \frac{\partial}{\partial \pi_k}\sum_{n=1}^N \sum_{k=1}^K
E[z_{nk}]\{\log \pi_k + \log \mathcal{P}(x_n|\theta)\} + \frac{\partial}{\partial \pi_k}\lambda(\sum_{j=1}^K \pi_j - 1)$$
$$ = \sum_{n=1}^N
\gamma(z_{nk})\frac{\partial}{\partial \pi_k}\{\log \pi_k + \log \mathcal{P}(x_n|\theta)\} + \frac{\partial}{\partial \pi_k} \lambda(\sum_{j=1}^K \pi_j - 1)$$
$$=\sum_{n=1}^N
\gamma(z_{nk})\frac{\partial}{\partial \pi_k}\{\log \pi_k\} + \frac{\partial}{\partial \pi_k} \lambda(\sum_{j=1}^K \pi_j - 1) $$
$$=\sum_{n=1}^N
\gamma(z_{nk})\frac{1}{\pi_k} + \lambda = 0$$
\\
Домножив на $\pi_k$, получаем
\begin{equation}
\sum_{n=1}^N \gamma(z_{nk}) + \pi_k \lambda = 0
\end{equation}
Просуммируем вдоль $k$
\begin{equation}
\sum_{n=1}^N \sum_{k=1}^K \gamma(z_{nk}) + \sum_{k=1}^K \pi_k \lambda = 0
\end{equation}
Применяя
$$\sum_{k=1}^K \gamma(z_{nk}) = 1$$
и
$$\sum_{k=1}^K \pi_k = 1$$
Из выражения (7) получаем
$$N + \lambda = 0$$
$$\lambda = -N$$
Далее, подставляя найденное $\lambda$ в выражение (6), получаем
$$\pi_k = - \frac{\sum_{n=1}^N\gamma(z_{nk})}{\lambda} = \frac{N_k}{N}$$
Наконец,
\begin{equation}
\pi_{k}^* = \frac{N_k}{N}
\end{equation}

$$s_n = \argmax_{s \in {1,..,S}^N} {\gamma_{ni}} $$

\textbf{Примечание.} Чтобы успешно обучить наши данные, следует правильно проинициализировать начальные значения входных параметров модели. Для этой задачи достаточно использовать алгоритм кластеризации KMeans++, который "разбивает" наши наблюдения на $S$ кластеров. Работа алгоритма основана на Методе Максимального Правдоподобия. На шаге Е мы определяем для каждого наблюдения ближайший кластер. На шаге М Вычисляем новое значение кластера, которое принимаем за среднее выборочное наблюдений, относящихся к данному кластеру. Алгоритм итерируется до тех пор, пока изменения логарифма правдоподобия не станет меньше $10^{-3}$

\subsubsection{Предсказание модели}

В результате работы алгоритма, необходимо предскзать наиболее вероятную послеовательность состояний, породивших наши наблюдения.
Для каждого наблюдения выбирается состояние, соответствующее наибольшей апостериорной вероятности.

\subsection{Скрытая Марковская Модель}

На практике условие о независимости  состояний между соседними наблюдениями в предыдущей модели не выполняется.

Поэтому, перейдем к Скрытой Марковской Модели второго порядка, чтобы учесть зависимость между состояниями соседних наблюдений.

\[
z_{(n+1),i} \mbox{ зависит от } z_{n,i}
\]

\begin{align*}
\pi_{k}^* = \frac{N_k}{N} 
\end{align*}

Введем понятие базовых состояний: $ S \in \{+, -, \operatorname{null}\}$.
Каждое из базовых состояний описывает ситуацию в одном образце. 

Семантика обозначений следующая:

$(+)$ - сигнал есть,  $(-)$ - шумовый сигнал, $\operatorname{(null)}$ - сигнала нет.

Отличие $\operatorname{(null)}$ от $(-)$ заключаются в полном отсутсвии сигнала.

Для задачи сравнения нам нужно множество состояний, описывающее, что происходит в каждом из образцов, то есть

$S^2 \in {(+,+),(-,-),(\operatorname{null},\operatorname{null}),
(+,-),(-,+),(\operatorname{null},-),(\operatorname{null},+),(-,\operatorname{null}),(+,\operatorname{null})}$



% У заключения нет номера главы
\section*{Заключение}

\bibliographystyle{ugost2008ls}
\bibliography{diploma.bib}
\end{document}
