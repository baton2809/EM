% Тут используется класс, установленный на сервере Papeeria. На случай, если
% текст понадобится редактировать где-то в другом месте, рядом лежит файл matmex-diploma-custom.cls
% который в момент своего создания был идентичен классу, установленному на сервере.
% Для того, чтобы им воспользоваться, замените matmex-diploma на matmex-diploma-custom
% Если вы работаете исключительно в Papeeria то мы настоятельно рекомендуем пользоваться
% классом matmex-diploma, поскольку он будет автоматически обновляться по мере внесения корректив
%
\documentclass{matmex-diploma}

\usepackage{amsmath}

\begin{document}
% Год, город, название университета и факультета предопределены,
% но можно и поменять.
% Если англоязычная титульная страница не нужна, то ее можно просто удалить.
\filltitle{ru}{
    chair              = {Кафедра информационных систем},
    title              = {Разработка программного компонента для проведения сравнительного анализа биологических данный FAIRE-seq},
    % Здесь указывается тип работы. Возможные значения:
    %   coursework - Курсовая работа
    %   diploma - Диплом специалиста
    %   master - Диплом магистра
    %   bachelor - Диплом бакалавра
    type               = {bachelor},
    position           = {студента},
    group              = 4511,
    author             = {Бутомов Артем Сергеевич},
    supervisorPosition = {},
    supervisor         = {Лебедев Сергей Андреевич},
    reviewerPosition   = {аспирант},
    reviewer           = {Сергушичев Алексей Александрович},
    chairHeadPosition  = {},
    chairHead          = {},
    university         = {Санкт-Петербургский национальный исследовательский университет информационных технологий, механики и оптики},
    faculty            = {Факультет информационных технологий и программирования},
%   city               = {Санкт-Петербург},
%   year               = {2013}
}
\filltitle{en}{
    chair              = {Chair of Information Systems},
    title              = {Development of a software component for a comparative analysis of the biological FAIRE-seq data},
    author             = {Artiom Butomov},
    supervisorPosition = {},
    supervisor         = {Sergei Lebedev},
    reviewerPosition   = {postgraduate},
    reviewer           = {Alexey Sergushichev},
    chairHeadPosition  = {},
    chairHead          = {},
    university         = {Saint Petersburg National Research University of Information Technologies, Mechanics and Optics},
    faculty            = {Faculty of Information Technology and Software Engineering},
}
\maketitle
\tableofcontents
% У введения нет номера главы
\section*{Введение}
ДНК (дезоксирибонуклеиновая кислота) --- длинная двухцепочечная молекула, являющаяся носителем генетической информации в биологических организмах.

Изучать пространственную структуру ДНК организма важно для понимания механизмов регуляции жизнидеятельности клетки.

Формальдегидная изоляция регуляторных элементов с последующим секвенированием (Formaldehyde-Assisted Isolation of Regulatory Elements sequencing, FAIRE-Seq) --- Это биологический протокол, позволяющий находить участки, в которых ДНК доступна для связывания белками. Суть работы метода заключается в том, что на ДНК, выделенную из клетки, "прикрепляют" нуклеосомы с помощью формальдегида. Затем ДНК фрагментируют с помощью ультразвука. После этого происходит "разделение" полученных фрагментов ДНК на две группы: участки связанные с белками и "свободные" участки. Далее "свободные" фрагменты "читают" с помощью секвенатора. И наконец, для каждого прочтения секвенатора определяют место в геноме исследуемого организма, откуда он был прочитан.

В контексте данной работы, геном "разбивается" на неперескающиеся отрезки фиксированной длины, называемые бинами. Подсчитывается количество прочтений, начинающихся внутри каждого отрезка. Таким образом, получатся вектор из неотрицательных целых чисел, именуемый вектором покрытия.

Из вектора покрытия можно сделать предположение о вероятности расплетения региона, чем больше значение элемента вектора, тем с большей вероятностью, что регион, соответствующий элементу, был расплетен.

Однако, рассматриваемый протокол не исключает возможности наличия ошибок в результатах биологического эксперемнта. Неточности метода FAIRE-seq обусловлены следующими моментами:
\begin{enumerate}
\item
Протокол работает с колонией клеток. Таким образом в результатах эксперимента мы видим некоторое среднее состояние по всем клеткам
\item
Этап фиксации не обладает 100\% КПД, то есть некоторые белки могут “отвалиться” 
\item
Этап разделения “свободных” и “связанных” фаз также неточен. Вместе со “свободными" вполне могут попасться и связанные фрагменты
\end{enumerate}

Так как в результате эксперемента появляется шум, данные FAIRE-seq удобно анализировать с помощью вероятностых моделей.

Цель данной работы - разработать математическую модель для проведения сравнительного анализа нескольких эксперементов биологический данных FAIRE-seq, научиться оценивать и контролировать число неверных предсказаний модели. 
\\\\
Для достижения цели были поставлены следующие задачи:
\begin{enumerate}
\item
Изучить предметную область
\item
Предложить несколько вероятностных моделей для сравнения экспериментов FAIRE-seq
\item
Реализовать модели в виде программы на языке Python
\item
Оценить эффективность полученной программы
\end{enumerate}

\section{Предлагаемые модели}
\subsection{Описание задачи}

Пусть $\vec{x}=(x_1,..,x_N)$ - вектор прочтений, построенный из какого-то BAM файла.
Сопоставим каждому наблюдению некоторую метку-состояние $s_n$ из множества базовых состояний $s=\{1,..,S\}$, истинные значения которых не знаем. 

Вероятностная модель позволяет найти наиболее правдоподобную последовательность состояний.

\newcommand{\argmax}{\mathop{\rm arg~max}\limits}
$$\hat{s}_{ML} = \argmax_{s \in {1,..,S}^N} \mathcal{P}(x,s;\theta)$$

\subsection{Смесь многомерных распределений Пуассона}

Будем считать, что мы работаем с двумя векторами покрытия.
Тогда наблюдение $x_n$ - это пара чисел, каждое из которых соответсвует одному вектору $\vec{x}=\{\vec{x_1},\vec{x_2}\}$.

Пусть $S = \{+, -\}$ — множество состояний, которые мы будем называть "базовыми" состояниями. Каждое из базовых состояний описывает ситуацию в одном образце, например, $(+)$ — сигнал есть, $(-)$ - шум или сигнала нет. 

Для задачи сравнения нам нужно множество состояний, описывающее, что происходит в каждом из образцов, то есть $S^2 = \{(+, +), (-, -), (+, -), (-, +)\}$.

Будем моделировать количество прочтений вдоль генома с помощью смеси многомерных распределений Пуасона.

Методом максимума правдоподобия найти решение довольно сложно, поскольку для этого требуется решить систему, где оцениваемые параметры зависят от наблюдаемой выборки $x$ и неизвестных значений скрытых состояний $s$. Асимптотическая сложность решения возрастет в $S^N$ раз.

Поэтому, будем искать приближенное решение с помощью EM-алгоритма, в котором правдоподобие оптимизируется до сходимости. Последовательность действий формируется следующим образом\cite{book:Bishop}:
\begin{enumerate}
\item
Инициализировать начальные значения параметров
\item
Вычислить нижнюю оценку на правдоподобие
\item
Найти новое значение параметров модели
\item
Вычислить логарифм правдоподобия и проверить на сходимость
\end{enumerate}

Выведем EM-алгоритм для смеси многомерных Пуасоновских испусканий.

\begin{equation}
\ln p(X;\pi,\lambda) = \sum_{n=1}^N \ln{\sum_{k=1}^K} \pi_k \mathcal{P}(x_n;\lambda_k)
\end{equation}

\begin{equation}
\gamma(z_{nk}) = \frac{\pi_k\mathcal{P}(x_n;\lambda_k)}{\sum_{j=1}^K\pi_j\mathcal{P}(x_n;\lambda_j)}
\end{equation}

\begin{equation}
\pi_{k}^* = \frac{N_k}{N}
\end{equation}

\subsection*{Шаг М}
% вместо |  - иполльзовать ;
$$\frac{\partial}{\partial \lambda_k}E[\log p(x|z;\theta)]$$
$$=\frac{\partial}{\partial \lambda_k}\sum_{n=1}^N \sum_{k=1}^K
E[z_{nk}]\{\log \pi_k + \log \mathcal{P}(x_n|\theta)\}$$
$$= \sum_{n=1}^N E[z_{nk}] \frac{\partial}{\partial \lambda_k} \log \mathcal{P}(x_n|\theta)$$
$$= \sum_{n=1}^N \gamma(z_{nk}) \frac{\partial}{\partial \lambda_k} \log {\frac{\lambda^{x_n} e^{-\lambda}}{x_n!}}$$
$$= \sum_{n=1}^N \gamma(z_{nk}) \frac{\partial}{\partial \lambda_k} (\log {\lambda_k}^{x_n} + \log e^{-\lambda_k} - \log x_n! )$$
$$= \sum_{n=1}^N \gamma(z_{nk}) \frac{\partial}{\partial \lambda_k} (x_n \log \lambda_k - \lambda_k - \log x_n! )$$
$$= \sum_{n=1}^N \gamma(z_{nk}) (\frac{x_n}{\lambda_k} - 1)= 0$$
\\\\
получаем
\begin{equation}
\lambda_k^* = \frac{1}{N_k}\sum_{n=1}^N\gamma(z_{nk})x_n
\end{equation}
\\\\
где
\begin{equation}
N_k = \sum_{n=1}^N\gamma(z_nk)
\end{equation}
Найдем новые значения априорных вероятностей.
Воспользуемся методом множителей Лагранжа для учета ограничений на вектор априорных вероятностей. 
$$\frac{\partial}{\partial \pi_k}( E[\log p(x|z;\theta)] + \lambda(\sum_{j=1}^K \pi_j - 1))$$
$$= \frac{\partial}{\partial \pi_k}\sum_{n=1}^N \sum_{k=1}^K
E[z_{nk}]\{\log \pi_k + \log \mathcal{P}(x_n|\theta)\} + \frac{\partial}{\partial \pi_k}\lambda(\sum_{j=1}^K \pi_j - 1)$$
$$ = \sum_{n=1}^N
\gamma(z_{nk})\frac{\partial}{\partial \pi_k}\{\log \pi_k + \log \mathcal{P}(x_n|\theta)\} + \frac{\partial}{\partial \pi_k} \lambda(\sum_{j=1}^K \pi_j - 1)$$
$$=\sum_{n=1}^N
\gamma(z_{nk})\frac{\partial}{\partial \pi_k}\{\log \pi_k\} + \frac{\partial}{\partial \pi_k} \lambda(\sum_{j=1}^K \pi_j - 1) $$
$$=\sum_{n=1}^N
\gamma(z_{nk})\frac{1}{\pi_k} + \lambda = 0$$
\\
Домножив на $\pi_k$, получаем
\begin{equation}
\sum_{n=1}^N \gamma(z_{nk}) + \pi_k \lambda = 0
\end{equation}
Просуммируем вдоль $k$
\begin{equation}
\sum_{n=1}^N \sum_{k=1}^K \gamma(z_{nk}) + \sum_{k=1}^K \pi_k \lambda = 0
\end{equation}
Применяя
$$\sum_{k=1}^K \gamma(z_{nk}) = 1$$
и
$$\sum_{k=1}^K \pi_k = 1$$
Из выражения (7) получаем
$$N + \lambda = 0$$
$$\lambda = -N$$
Далее, подставляя найденное $\lambda$ в выражение (6), получаем
$$\pi_k = - \frac{\sum_{n=1}^N\gamma(z_{nk})}{\lambda} = \frac{N_k}{N}$$
Наконец,
\begin{align*}
\pi_{k}^* = \frac{N_k}{N} 
\end{align*}

$$s_n = \argmax_{s \in {1,..,S}^N} {\gamma_{ni}} $$

\textbf{Примечание.} Чтобы успешно обучить наши данные, следует правильно проинициализировать начальные значения входных параметров модели. Для этой задачи достаточно использовать алгоритм кластеризации KMeans++, который "разбивает" наши наблюдения на $S$ кластеров. Работа алгоритма основана на Методе Максимального Правдоподобия. На шаге Е мы определяем для каждого наблюдения ближайший кластер. На шаге М Вычисляем новое значение кластера, которое принимаем за среднее выборочное наблюдений, относящихся к данному кластеру. Алгоритм итерируется до тех пор, пока изменения логарифма правдоподобия не станет меньше $10^{-3}$. В результате, начальные значений параметров Пуасоновского распределения можно принять за значения кластеров.

\subsubsection{Предсказание модели}

В результате работы алгоритма, необходимо предскзать наиболее вероятную послеовательность состояний, породивших наши наблюдения.
Для каждого наблюдения выбирается состояние, соответствующее наибольшей апостериорной вероятности.

\subsection{Скрытая Марковская Модель}

На практике условие о независимости  состояний между соседними наблюдениями в предыдущей модели не выполняется.

Поэтому, перейдем к Скрытой Марковской Модели второго порядка, чтобы учесть зависимость между состояниями соседних наблюдений.

\[
z_{(n+1),i} \mbox{ зависит от } z_{n,i}
\]

Введем понятие базовых состояний: $ S \in \{+, -, \operatorname{null}\}$.
Каждое из базовых состояний описывает ситуацию в одном образце. 
\\
Семантика обозначений следующая:
\\
$(+)$ - сигнал есть,  $(-)$ - шумовый сигнал, $\operatorname{(null)}$ - сигнала нет.
\\\\
\textbf{Замечание.} Отличие $\operatorname{(null)}$ от $(-)$ заключаются в полном отсутсвии сигнала.
\\\\
Для задачи сравнения нам нужно множество состояний, описывающее, что происходит в каждом из образцов, то есть
\\\\
$S^2 \in {(+,+),(-,-),(\operatorname{null},\operatorname{null}),
(+,-),(-,+),(\operatorname{null},-),(\operatorname{null},+),(-,\operatorname{null}),(+,\operatorname{null})}$
\\\\
Состояние $S_t$ с одинаковым базовыми состояниями $(+,+),(-,-),(\operatorname{null},\operatorname{null})$ означает, что данные сравниваемых образцов наблюдения $x_t$ похожи между собой.
\\\\
Пусть
\\\\
$\pi = (\pi_1,..,\pi_S)$ - априорные вероятности состояний.
\\
$\mathcal{A}$ - матрица вероятностей перехода между состояниями.
\\
$\lambda = (\lambda_1,..,\lambda_S)$ - параметры многомерного распределения Пуасона.
\\\\
Тогда, функция правдоподобия определяется как

$$p = ...$$
\\\\
% Рисунок, размещенный с предпочтением "вверху страницы"
\begin{figure}[h]
\label{разрыв_функции}
\centering
\includegraphics[scale=0.9]{plate_states3.png}
\caption{решетка состояний}
\end{figure}
\\\\
Решетка представляет собой диаграмму переходов между скрытыми состояниями модели. Красным светом выделены состояния, в котором базовые состояния похожи, то есть $(+,+),(-,-),(\operatorname{null},\operatorname{null})$

\subsection*{Шаг E}
$$\gamma_{ni}=\frac{\alpha_{ni}\beta_{ni}}{\sum_{j=1}^S\alpha_{nj}\beta_{nj}}$$
\\\\
$$\xi_{nij}=\frac{\alpha_{(n-1),i}\mathcal{A}_{ij}\mathcal{P}(x_n;\lambda_j)\beta_{nj}}{\sum_{i'=1}^S\sum_{j'=1}^S\alpha_{(n-1),i'}A_{i'j'}\mathcal{P}(x_n;\lambda_{j'})\beta_{nj'}}$$
\\\\
Где, 
\\\\
$\alpha_{ni}=p(s_{ni}=1,x_1,x_2,..x_n;\theta)$
\\\\
$\beta_{ni}=p(x_{n+1}, ..,x_N; s_{ni}=1,\theta)$
\\\\
Вычисления $\alpha$ и $\beta$ производится с помощью алгоритма прямого-обратного хода:
\\
$$\alpha_{1i}=\pi_i\mathcal{P}$$
\\
$$\beta_{Ni}=1$$
\\
$$\alpha_{ni}=\mathcal{P}(x_n;\lambda_i)\sum_{j=1}^S\alpha_{(n-1),j}A_{ji}$$
\\
$$\beta_{ni}=\sum_{j=1}^S A_{ij}\mathcal{P}(x_{n+1};\lambda_j)\beta_{(n+1),j}$$
\\\\
\\\\
\subsection*{Шаг М}
Новые значения параметров модели
$$\pi_i^*=\gamma_i1$$
\\
$$A_{ij}^*=\frac{\sum_{n=2}^N\xi_{nij}}{\sum_{j'=1}^S\sum_{n=2}^N\xi_{nij}\xi_{nij'}}$$
\\
$$\lambda_i^* = \frac{\sum_{n=1}^N\gamma(z_{ni})x_n}{\sum_{n=1}^N\gamma(z_{ni})}$$

\textbf{Замечание.} В алгоритме прямого-обратного хода может быть underflow - это значит, что не хватает точности чисел с плавающей точкой.
Поэтому удобно проводить вычисления в логарифмах.

\subsection{Выбор модели}
Для задачи сравнения двух образцов была выбрана Скрытая Марковская Модель.
В частном случае, для анализа одного биологического образца СММ более правдоподобнее, чем смесь Пуасоновских испусканий.
%% запихнуть табличку двухстолбчатую со значениями правдоподобий некоторых хромосом: первый ст. - Смесь, второй - СММ.
Это значит, что модель, в которой предполагается зависимость между состояниями соседних наблюдений, более правдоподобная.

\section{Оценка модели/ей}

\subsection{Оценка и контроль FDR}

% У заключения нет номера главы
\section*{Заключение}

\bibliographystyle{ugost2008ls}
\bibliography{diploma.bib}
\end{document}
